{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9437119,"sourceType":"datasetVersion","datasetId":5734287}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4591013","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertForSequenceClassification, BertTokenizer,AdamW,get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification,Trainer, TrainingArguments","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T04:26:15.233725Z","iopub.execute_input":"2024-09-20T04:26:15.234647Z","iopub.status.idle":"2024-09-20T04:26:32.630923Z","shell.execute_reply.started":"2024-09-20T04:26:15.234595Z","shell.execute_reply":"2024-09-20T04:26:32.630133Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dataset=pd.read_csv('/kaggle/input/mimic-iii/LOS_WEEKS_adm_train.csv')\nval_dataset=pd.read_csv('/kaggle/input/mimic-iii/LOS_WEEKS_adm_val.csv')\ntest_dataset=pd.read_csv('/kaggle/input/mimic-iii/LOS_WEEKS_adm_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:26:32.632806Z","iopub.execute_input":"2024-09-20T04:26:32.633394Z","iopub.status.idle":"2024-09-20T04:26:34.469860Z","shell.execute_reply.started":"2024-09-20T04:26:32.633361Z","shell.execute_reply":"2024-09-20T04:26:34.469056Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import dataloader\nfrom torch import nn\n\nclass EnsembleModel(nn.Module):\n    def __init__(self, model1):\n        super(EnsembleModel, self).__init__()\n        self.model1 = model1\n    def forward(self, input_ids, attention_mask):\n        output1 = self.model1(input_ids=input_ids, attention_mask=attention_mask)[0]\n        avg_output= output1\n        return output1","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:26:34.471069Z","iopub.execute_input":"2024-09-20T04:26:34.471430Z","iopub.status.idle":"2024-09-20T04:26:34.477871Z","shell.execute_reply.started":"2024-09-20T04:26:34.471388Z","shell.execute_reply":"2024-09-20T04:26:34.477011Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoConfig\nconfig=AutoConfig.from_pretrained('bvanaken/CORe-clinical-outcome-biobert-v1',\n                                  num_labels=4,\n                                  hidden_dropout_prob=0.2,\n                                  attention_probs_dropout_prob=0.2)\n\ncore_model=AutoModelForSequenceClassification.from_pretrained('bvanaken/CORe-clinical-outcome-biobert-v1',\n                                                              config=config)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:26:34.478981Z","iopub.execute_input":"2024-09-20T04:26:34.479294Z","iopub.status.idle":"2024-09-20T04:26:37.880915Z","shell.execute_reply.started":"2024-09-20T04:26:34.479253Z","shell.execute_reply":"2024-09-20T04:26:37.880118Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/428 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d96f303021e4e3d8a59831719ec6eaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d180ff87fc3a49ffb9ed8ed0ab0cfb4a"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bvanaken/CORe-clinical-outcome-biobert-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer=AutoTokenizer.from_pretrained('bvanaken/CORe-clinical-outcome-biobert-v1')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:26:37.883321Z","iopub.execute_input":"2024-09-20T04:26:37.883657Z","iopub.status.idle":"2024-09-20T04:26:38.450315Z","shell.execute_reply.started":"2024-09-20T04:26:37.883595Z","shell.execute_reply":"2024-09-20T04:26:38.449363Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b93a2f388164344bfcfc6ff38170e42"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_encodings = tokenizer(train_dataset['text'].tolist(), truncation=True, padding=True, max_length = 512)\nval_encodings = tokenizer(val_dataset['text'].tolist(), truncation=True, padding=True,  max_length = 512)\ntest_encodings = tokenizer(test_dataset['text'].tolist(), truncation=True, padding=True , max_length = 512)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:26:38.451480Z","iopub.execute_input":"2024-09-20T04:26:38.451798Z","iopub.status.idle":"2024-09-20T04:27:15.315704Z","shell.execute_reply.started":"2024-09-20T04:26:38.451765Z","shell.execute_reply":"2024-09-20T04:27:15.314886Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class LosDataset(torch.utils.data.Dataset):\n    def __init__(self,encodings,labels):\n        self.encodings=encodings\n        self.labels=labels\n\n    def __getitem__(self,idx):\n        item={key:torch.tensor(val[idx]) for key,val in self.encodings.items()}\n        item['labels']=torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:15.316884Z","iopub.execute_input":"2024-09-20T04:27:15.317217Z","iopub.status.idle":"2024-09-20T04:27:15.323557Z","shell.execute_reply.started":"2024-09-20T04:27:15.317182Z","shell.execute_reply":"2024-09-20T04:27:15.322655Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset = LosDataset(train_encodings, train_dataset['los_label'].tolist())\nval_dataset   = LosDataset(val_encodings, val_dataset['los_label'].tolist())\ntest_dataset  = LosDataset(test_encodings, test_dataset['los_label'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:15.325139Z","iopub.execute_input":"2024-09-20T04:27:15.325696Z","iopub.status.idle":"2024-09-20T04:27:15.343945Z","shell.execute_reply.started":"2024-09-20T04:27:15.325660Z","shell.execute_reply":"2024-09-20T04:27:15.343074Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW , get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,roc_auc_score\nfrom tqdm import tqdm\nfrom torch import nn\nimport numpy as np\n\nensemble_model=EnsembleModel(core_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:15.345282Z","iopub.execute_input":"2024-09-20T04:27:15.345540Z","iopub.status.idle":"2024-09-20T04:27:15.352996Z","shell.execute_reply.started":"2024-09-20T04:27:15.345511Z","shell.execute_reply":"2024-09-20T04:27:15.352152Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import os\n\n# list all files in the current directory\nfiles = os.listdir('.')\n\n# filter the ones that start with 'CORE_baseline'\ncore_models = [f for f in files if f.startswith('CORE_baseline')]\n\nif core_models:\n    print(\"Found models starting with 'CORE_baseline':\")\n    for model in core_models:\n        print(model)\n        \n    # get the first (and supposedly only) model\n    model_path = core_models[0]\n\n    # load the model state\n    ensemble_model.load_state_dict(torch.load(model_path))\n    print(\"Loaded Model\")\nelse:\n    print(\"No models found starting with 'CORE_baseline'.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:15.354090Z","iopub.execute_input":"2024-09-20T04:27:15.354397Z","iopub.status.idle":"2024-09-20T04:27:15.362988Z","shell.execute_reply.started":"2024-09-20T04:27:15.354366Z","shell.execute_reply":"2024-09-20T04:27:15.361998Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"No models found starting with 'CORE_baseline'.\n","output_type":"stream"}]},{"cell_type":"code","source":"device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nensemble_model=ensemble_model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:15.364165Z","iopub.execute_input":"2024-09-20T04:27:15.364897Z","iopub.status.idle":"2024-09-20T04:27:15.733129Z","shell.execute_reply.started":"2024-09-20T04:27:15.364855Z","shell.execute_reply":"2024-09-20T04:27:15.732305Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:15.734477Z","iopub.execute_input":"2024-09-20T04:27:15.734904Z","iopub.status.idle":"2024-09-20T04:27:15.740659Z","shell.execute_reply.started":"2024-09-20T04:27:15.734857Z","shell.execute_reply":"2024-09-20T04:27:15.739669Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epochs = 200\nbest_roc_auc = 0.701894\nmin_delta = 0.0001\nearly_stopping_count = 0\nearly_stopping_patience = 3\ngradient_accumulation_steps = 10\nbest_model_path = \"best_model.pth\"\n\n\noptimizer = AdamW(ensemble_model.parameters(), lr=1e-5, weight_decay=0.01)\n\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=50, \n    num_training_steps=len(train_loader) * epochs // gradient_accumulation_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:15.741736Z","iopub.execute_input":"2024-09-20T04:27:15.742065Z","iopub.status.idle":"2024-09-20T04:27:16.146374Z","shell.execute_reply.started":"2024-09-20T04:27:15.742032Z","shell.execute_reply":"2024-09-20T04:27:16.145405Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nensemble_model=ensemble_model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:16.150660Z","iopub.execute_input":"2024-09-20T04:27:16.150981Z","iopub.status.idle":"2024-09-20T04:27:16.159790Z","shell.execute_reply.started":"2024-09-20T04:27:16.150947Z","shell.execute_reply":"2024-09-20T04:27:16.158983Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torch.nn import functional as F\n# Training\nfor epoch in range(5, epochs):\n    ensemble_model.train()\n    train_loss = 0\n    for step, batch in enumerate(tqdm(train_loader)):\n        optimizer.zero_grad() if step % gradient_accumulation_steps == 0 else None\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = ensemble_model(input_ids, attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        (loss / gradient_accumulation_steps).backward()\n        train_loss += loss.item()\n        if (step + 1) % gradient_accumulation_steps == 0 or (step + 1) == len(train_loader):\n            optimizer.step()\n            scheduler.step()\n    ensemble_model.eval()\n    val_loss=0\n    val_preds=[]\n    val_labels=[]\n    with torch.no_grad():\n        for batch in tqdm(val_loader):\n            input_ids=batch['input_ids'].to(device)\n            attention_mask=batch['attention_mask'].to(device)\n            labels=batch['labels'].to(device)\n            outputs=ensemble_model(input_ids,attention_mask=attention_mask)\n            loss=nn.CrossEntropyLoss()(outputs,labels)\n            val_loss+=loss.item()\n            val_preds.append(F.softmax(outputs,dim=1).cpu().numpy())\n            val_labels.append(labels.cpu().numpy())\n\n    val_preds=np.concatenate(val_preds)\n    val_labels=np.concatenate(val_labels)\n    val_loss /=len(val_loader)\n    train_loss /=len(train_loader)\n    print(f'Epoch {epoch+1}/{epochs}')\n    print(f'Train Loss: {train_loss:.4f}')\n    print(f'Val Loss: {val_loss:.4f}')\n\n    val_preds_class =np.argmax(val_preds, axis=1)\n    acuuracy=accuracy_score(val_labels,val_preds_class)\n    recall=recall_score(val_labels,val_preds_class,average='weighted')\n    precision=precision_score(val_labels,val_preds_class,average='weighted')\n    f1=f1_score(val_labels,val_preds_class,average='weighted')\n    mirco_f1= f1_score(val_labels,val_preds_class,average='micro')\n    macro_roc_auc=roc_auc_score(val_labels,val_preds,multi_class='ovo',average='macro')\n    #weighted_roc_auc=roc_auc_score(val_labels,val_preds,multi_class='ovo',average='weighted')\n    print(f'Accuracy: {acuuracy}')\n    print(f'Recall: {recall}')\n    print(f'Precision: {precision}')\n    print(f'F1: {f1}')\n    print(f'Micro F1: {mirco_f1}')\n    print(f'Macro ROC AUC: {macro_roc_auc}')\n    #print(f'Weighted ROC AUC: {weighted_roc_auc:.4f}')\n\n    #implement early stopping\n\n    if epoch >0 and macro_roc_auc - best_roc_auc < min_delta:\n        early_stopping_count += 1\n        print(f\"Early stopping count: {early_stopping_count}/{early_stopping_patience}\")\n        if early_stopping_count >= early_stopping_patience:\n            print(\"Early stopping triggered.\")\n            break\n    else:\n        best_roc_auc = macro_roc_auc\n        early_stopping_count = 0\n        torch.save(ensemble_model.state_dict(), f\"CORE_baseline_epoch_{epoch}roc_{best_roc_auc}.pth\")\n        print(\"Model saved.\")\n        \n\n    \n           \n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:27:16.161234Z","iopub.execute_input":"2024-09-20T04:27:16.161494Z","iopub.status.idle":"2024-09-20T06:57:25.903229Z","shell.execute_reply.started":"2024-09-20T04:27:16.161465Z","shell.execute_reply":"2024-09-20T06:57:25.902104Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|██████████| 3803/3803 [47:50<00:00,  1.32it/s]\n100%|██████████| 549/549 [02:08<00:00,  4.27it/s]\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/200\nTrain Loss: 1.3176\nVal Loss: 1.2873\nAccuracy: 0.3689364609428376\nRecall: 0.36893646094283755\nPrecision: 0.3189242806190809\nF1: 0.33851006678610823\nMicro F1: 0.3689364609428376\nMacro ROC AUC: 0.6435483771558027\nEarly stopping count: 1/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3803/3803 [47:57<00:00,  1.32it/s]\n100%|██████████| 549/549 [02:08<00:00,  4.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/200\nTrain Loss: 1.2338\nVal Loss: 1.2285\nAccuracy: 0.3939877021179686\nRecall: 0.3939877021179686\nPrecision: 0.42792509760144676\nF1: 0.35424250119704603\nMicro F1: 0.3939877021179686\nMacro ROC AUC: 0.6785975665068826\nEarly stopping count: 2/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3803/3803 [47:56<00:00,  1.32it/s]\n100%|██████████| 549/549 [02:08<00:00,  4.28it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 8/200\nTrain Loss: 1.1924\nVal Loss: 1.2058\nAccuracy: 0.41038487815987246\nRecall: 0.41038487815987246\nPrecision: 0.41827392031167565\nF1: 0.3958617528785462\nMicro F1: 0.41038487815987246\nMacro ROC AUC: 0.6957385184280573\nEarly stopping count: 3/3\nEarly stopping triggered.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nfiles=os.listdir('.')\ncore_models=[f for f in files if f.startswith('CORE_baseline')]\n\n\nif core_models:\n    print(\"Found models starting with 'CORE_baseline':\")\n    for model in core_models:\n        print(model)\n\n    model_path=core_models[0]\n    ensemble_model.load_state_dict(torch.load(model_path))\n    print(\"Loaded Model\")\nelse:\n    print(\"No models found starting with 'CORE_baseline'.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T06:57:25.904710Z","iopub.execute_input":"2024-09-20T06:57:25.905035Z","iopub.status.idle":"2024-09-20T06:57:25.912676Z","shell.execute_reply.started":"2024-09-20T06:57:25.904993Z","shell.execute_reply":"2024-09-20T06:57:25.911656Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"No models found starting with 'CORE_baseline'.\n","output_type":"stream"}]},{"cell_type":"code","source":"ensemble_model.eval()\n\ntest_preds =[]\ntest_lables =[]\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader):\n        input_ids=batch['input_ids'].to(device)\n        attention_mask=batch['attention_mask'].to(device)\n        labels=batch['labels'].to(device)\n        outputs=ensemble_model(input_ids,attention_mask=attention_mask)\n        test_preds.append(F.softmax(outputs,dim=1).cpu().numpy())\n        test_lables.append(labels.cpu().numpy())\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T06:57:25.914206Z","iopub.execute_input":"2024-09-20T06:57:25.914660Z","iopub.status.idle":"2024-09-20T07:01:43.353454Z","shell.execute_reply.started":"2024-09-20T06:57:25.914588Z","shell.execute_reply":"2024-09-20T07:01:43.352527Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|██████████| 1100/1100 [04:17<00:00,  4.27it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_preds=np.concatenate(test_preds)\ntest_labels=np.concatenate(test_lables) \n\ntest_preds_class=np.argmax(test_preds,axis=1)\naccuracy = accuracy_score(test_labels, test_preds_class)\nrecall = recall_score(test_labels, test_preds_class, average='weighted')\nprecision = precision_score(test_labels, test_preds_class, average='weighted')\nf1 = f1_score(test_labels, test_preds_class, average='weighted')\nmicro_f1 = f1_score(test_labels, test_preds_class, average='micro')\nmacro_roc_auc = roc_auc_score(test_labels, test_preds, multi_class='ovo', average='macro')\nprint(f'Accuracy: {accuracy}')\nprint(f'Recall: {recall}')\nprint(f'Precision: {precision}')\nprint(f'F1: {f1}')\nprint(f'Micro F1: {micro_f1}')\nprint(f'Macro ROC AUC: {macro_roc_auc}')","metadata":{"execution":{"iopub.status.busy":"2024-09-20T07:01:43.354685Z","iopub.execute_input":"2024-09-20T07:01:43.354988Z","iopub.status.idle":"2024-09-20T07:01:43.398438Z","shell.execute_reply.started":"2024-09-20T07:01:43.354956Z","shell.execute_reply":"2024-09-20T07:01:43.397581Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Accuracy: 0.42559963623962715\nRecall: 0.42559963623962715\nPrecision: 0.44011706747668994\nF1: 0.4135338519759182\nMicro F1: 0.42559963623962715\nMacro ROC AUC: 0.7062879105845056\n","output_type":"stream"}]}]}