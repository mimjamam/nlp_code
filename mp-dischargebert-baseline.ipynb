{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9536973,"sourceType":"datasetVersion","datasetId":5808925}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertForSequenceClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-05T13:13:55.476703Z","iopub.execute_input":"2024-10-05T13:13:55.477795Z","iopub.status.idle":"2024-10-05T13:14:13.781968Z","shell.execute_reply.started":"2024-10-05T13:13:55.477715Z","shell.execute_reply":"2024-10-05T13:14:13.781010Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/mp-data/MP_IN_adm_train.csv')\nval_dataset = pd.read_csv('/kaggle/input/mp-data/MP_IN_adm_val.csv')\ntest_dataset = pd.read_csv('/kaggle/input/mp-data/MP_IN_adm_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:14:13.783833Z","iopub.execute_input":"2024-10-05T13:14:13.784589Z","iopub.status.idle":"2024-10-05T13:14:16.060326Z","shell.execute_reply.started":"2024-10-05T13:14:13.784534Z","shell.execute_reply":"2024-10-05T13:14:16.059290Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch import nn\n\nclass EnsembleModel(nn.Module):\n    def __init__(self, model1):\n        super(EnsembleModel, self).__init__()\n        self.model1 = model1\n\n    def forward(self, input_ids, attention_mask):\n        output1 = self.model1(input_ids, attention_mask=attention_mask)[0]\n        avg_output = output1\n        return avg_output","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:14:16.061703Z","iopub.execute_input":"2024-10-05T13:14:16.062711Z","iopub.status.idle":"2024-10-05T13:14:16.069051Z","shell.execute_reply.started":"2024-10-05T13:14:16.062664Z","shell.execute_reply":"2024-10-05T13:14:16.068050Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoConfig\n\n\nconfig = AutoConfig.from_pretrained('emilyalsentzer/Bio_Discharge_Summary_BERT', \n                                    num_labels=2, \n                                    hidden_dropout_prob=0.2, \n                                    attention_probs_dropout_prob=0.2)\n\n\ncore_model = AutoModelForSequenceClassification.from_pretrained('emilyalsentzer/Bio_Discharge_Summary_BERT', config=config)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:14:16.071945Z","iopub.execute_input":"2024-10-05T13:14:16.072479Z","iopub.status.idle":"2024-10-05T13:14:19.173097Z","shell.execute_reply.started":"2024-10-05T13:14:16.072432Z","shell.execute_reply":"2024-10-05T13:14:19.172163Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d6dea1b3dff4e838c16fdca34d97014"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d0d27e25f0744d0b5171c526d616270"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_Discharge_Summary_BERT and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n\ntokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_Discharge_Summary_BERT')","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:14:19.174242Z","iopub.execute_input":"2024-10-05T13:14:19.174554Z","iopub.status.idle":"2024-10-05T13:14:19.681707Z","shell.execute_reply.started":"2024-10-05T13:14:19.174520Z","shell.execute_reply":"2024-10-05T13:14:19.680795Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c16a2448380406a976a4ed284f679e3"}},"metadata":{}}]},{"cell_type":"code","source":"\ntrain_encodings = tokenizer(train_dataset['text'].tolist(), truncation=True, padding=True, max_length = 512)\nval_encodings = tokenizer(val_dataset['text'].tolist(), truncation=True, padding=True,  max_length = 512)\ntest_encodings = tokenizer(test_dataset['text'].tolist(), truncation=True, padding=True , max_length = 512)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:14:19.682838Z","iopub.execute_input":"2024-10-05T13:14:19.683178Z","iopub.status.idle":"2024-10-05T13:15:01.956896Z","shell.execute_reply.started":"2024-10-05T13:14:19.683126Z","shell.execute_reply":"2024-10-05T13:15:01.956069Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nclass LosDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:01.958170Z","iopub.execute_input":"2024-10-05T13:15:01.958557Z","iopub.status.idle":"2024-10-05T13:15:01.965759Z","shell.execute_reply.started":"2024-10-05T13:15:01.958503Z","shell.execute_reply":"2024-10-05T13:15:01.964865Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset = LosDataset(train_encodings, train_dataset['hospital_expire_flag'].tolist())\nval_dataset = LosDataset(val_encodings, val_dataset['hospital_expire_flag'].tolist())\ntest_dataset = LosDataset(test_encodings, test_dataset['hospital_expire_flag'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:01.967000Z","iopub.execute_input":"2024-10-05T13:15:01.967421Z","iopub.status.idle":"2024-10-05T13:15:01.983780Z","shell.execute_reply.started":"2024-10-05T13:15:01.967374Z","shell.execute_reply":"2024-10-05T13:15:01.982890Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\nfrom tqdm import tqdm\nfrom torch import nn\nimport numpy as np\n\n\nensemble_model = EnsembleModel(core_model)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:01.985031Z","iopub.execute_input":"2024-10-05T13:15:01.985382Z","iopub.status.idle":"2024-10-05T13:15:01.992098Z","shell.execute_reply.started":"2024-10-05T13:15:01.985341Z","shell.execute_reply":"2024-10-05T13:15:01.991198Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import os\n\n\nfiles = os.listdir('.')\n\n\ncore_models = [f for f in files if f.startswith('dischargeBERT_baseline_MP')]\n\nif core_models:\n    print(\"Found models starting with 'dischargeBERT_baseline_MP':\")\n    for model in core_models:\n        print(model)\n        \n   \n    model_path = core_models[0]\n\n    \n    ensemble_model.load_state_dict(torch.load(model_path))\n    print(\"Loaded Model\")\nelse:\n    print(\"No models found starting with 'dischargeBERT_baseline_MP'.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:01.995559Z","iopub.execute_input":"2024-10-05T13:15:01.996355Z","iopub.status.idle":"2024-10-05T13:15:02.003184Z","shell.execute_reply.started":"2024-10-05T13:15:01.996310Z","shell.execute_reply":"2024-10-05T13:15:02.002198Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"No models found starting with 'dischargeBERT_baseline_MP'.\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nensemble_model = ensemble_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:02.004336Z","iopub.execute_input":"2024-10-05T13:15:02.004737Z","iopub.status.idle":"2024-10-05T13:15:02.371387Z","shell.execute_reply.started":"2024-10-05T13:15:02.004697Z","shell.execute_reply":"2024-10-05T13:15:02.370589Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\ntrain_loader = DataLoader(train_dataset, batch_size=18, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=18, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=18, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:02.372498Z","iopub.execute_input":"2024-10-05T13:15:02.372807Z","iopub.status.idle":"2024-10-05T13:15:02.378175Z","shell.execute_reply.started":"2024-10-05T13:15:02.372770Z","shell.execute_reply":"2024-10-05T13:15:02.377252Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\nepochs = 200\nbest_roc_auc = 0.0\nmin_delta = 0.0001\nearly_stopping_count = 0\nearly_stopping_patience = 3\ngradient_accumulation_steps = 10\nbest_model_path = \"best_model.pth\"\n\n\noptimizer = AdamW(ensemble_model.parameters(), lr=1e-5, weight_decay=0.01)\n\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=50, \n    num_training_steps=len(train_loader) * epochs // gradient_accumulation_steps\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:02.379358Z","iopub.execute_input":"2024-10-05T13:15:02.379671Z","iopub.status.idle":"2024-10-05T13:15:02.810284Z","shell.execute_reply.started":"2024-10-05T13:15:02.379639Z","shell.execute_reply":"2024-10-05T13:15:02.809495Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.nn import functional as F\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Training\nfor epoch in range(epochs):\n    ensemble_model.train()\n    train_loss = 0\n    for step, batch in enumerate(tqdm(train_loader)):\n        optimizer.zero_grad() if step % gradient_accumulation_steps == 0 else None\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = ensemble_model(input_ids, attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        (loss / gradient_accumulation_steps).backward()\n        train_loss += loss.item()\n        if (step + 1) % gradient_accumulation_steps == 0 or (step + 1) == len(train_loader):\n            optimizer.step()\n            scheduler.step()\n\n    ensemble_model.eval()\n    val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        for batch in tqdm(val_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = ensemble_model(input_ids, attention_mask)\n            loss = nn.CrossEntropyLoss()(outputs, labels)\n            val_loss += loss.item()\n            val_preds.append(F.softmax(outputs, dim=1).cpu().numpy())\n            val_labels.append(labels.cpu().numpy())\n            \n    val_preds = np.concatenate(val_preds)\n    val_labels = np.concatenate(val_labels)\n    val_loss /= len(val_loader)\n    train_loss /= len(train_loader)\n    print(f'Epoch: {epoch+1}/{epochs}, Training Loss: {train_loss}, Validation Loss: {val_loss}')\n\n    # Calculate metrics\n    val_preds_class = np.argmax(val_preds, axis=1)\n    accuracy = accuracy_score(val_labels, val_preds_class)\n    recall = recall_score(val_labels, val_preds_class)\n    precision = precision_score(val_labels, val_preds_class)\n    f1 = f1_score(val_labels, val_preds_class)\n    roc_auc = roc_auc_score(val_labels, val_preds[:, 1])\n\n    print(f'Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}, F1: {f1}, Roc Auc: {roc_auc}')\n\n    # Implement early stopping\n    if epoch > 0 and roc_auc - best_roc_auc < min_delta:\n        early_stopping_count += 1\n        print(f'EarlyStopping counter: {early_stopping_count} out of {early_stopping_patience}')\n        if early_stopping_count >= early_stopping_patience:\n            print('Early stopping')\n            break\n    else:\n        best_roc_auc = roc_auc\n        early_stopping_count = 0\n        torch.save(ensemble_model.state_dict(), f\"dischargeBERT_baseline_MP_epoch_{epoch}roc_{best_roc_auc}.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T13:15:02.811454Z","iopub.execute_input":"2024-10-05T13:15:02.811765Z","iopub.status.idle":"2024-10-06T00:07:00.065500Z","shell.execute_reply.started":"2024-10-05T13:15:02.811732Z","shell.execute_reply":"2024-10-06T00:07:00.064579Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 1887/1887 [56:36<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1/200, Training Loss: 0.34972611292367517, Validation Loss: 0.30640777426979915\nAccuracy: 0.8944580277098615, Recall: 0.0, Precision: 0.0, F1: 0.0, Roc Auc: 0.7379372213085197\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:42<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2/200, Training Loss: 0.292095772308067, Validation Loss: 0.27782470833905887\nAccuracy: 0.8987367563162184, Recall: 0.09652509652509653, Precision: 0.6329113924050633, F1: 0.16750418760469013, Roc Auc: 0.7978359908883826\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:40<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3/200, Training Loss: 0.2712681589941294, Validation Loss: 0.2756115767709065\nAccuracy: 0.8989405052974735, Recall: 0.06756756756756757, Precision: 0.7291666666666666, F1: 0.1236749116607774, Roc Auc: 0.8035795639440286\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:46<00:00,  1.81s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4/200, Training Loss: 0.2557579556615282, Validation Loss: 0.2740489991565982\nAccuracy: 0.8993480032599837, Recall: 0.09266409266409266, Precision: 0.6666666666666666, F1: 0.16271186440677965, Roc Auc: 0.8119251369820846\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:40<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5/200, Training Loss: 0.2456650483739332, Validation Loss: 0.2690746789941421\nAccuracy: 0.8983292583537082, Recall: 0.16988416988416988, Precision: 0.5605095541401274, F1: 0.2607407407407407, Roc Auc: 0.8181858558851727\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:42<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6/200, Training Loss: 0.23161814187193872, Validation Loss: 0.29037770774938687\nAccuracy: 0.8985330073349633, Recall: 0.06563706563706563, Precision: 0.7083333333333334, F1: 0.12014134275618372, Roc Auc: 0.8060263322222321\nEarlyStopping counter: 1 out of 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:43<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:32<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7/200, Training Loss: 0.22028103728236254, Validation Loss: 0.28206058033492976\nAccuracy: 0.8966992665036675, Recall: 0.11776061776061776, Precision: 0.5495495495495496, F1: 0.19395866454689983, Roc Auc: 0.8149396223428114\nEarlyStopping counter: 2 out of 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:41<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8/200, Training Loss: 0.21033138630094395, Validation Loss: 0.2813579781124225\nAccuracy: 0.8983292583537082, Recall: 0.19305019305019305, Precision: 0.5524861878453039, F1: 0.2861230329041488, Roc Auc: 0.8195442432344482\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:44<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9/200, Training Loss: 0.19397635741636085, Validation Loss: 0.29902877906958264\nAccuracy: 0.8995517522412388, Recall: 0.15057915057915058, Precision: 0.5954198473282443, F1: 0.24036979969183356, Roc Auc: 0.8068290956104168\nEarlyStopping counter: 1 out of 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:44<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10/200, Training Loss: 0.1807367366096513, Validation Loss: 0.3079958547541237\nAccuracy: 0.8985330073349633, Recall: 0.11583011583011583, Precision: 0.6, F1: 0.1941747572815534, Roc Auc: 0.8048381280727522\nEarlyStopping counter: 2 out of 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1887/1887 [56:44<00:00,  1.80s/it]\n100%|██████████| 273/273 [02:33<00:00,  1.78it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 11/200, Training Loss: 0.16316930512282218, Validation Loss: 0.3059203746581907\nAccuracy: 0.8920130399348003, Recall: 0.1776061776061776, Precision: 0.46938775510204084, F1: 0.25770308123249297, Roc Auc: 0.8080012488896317\nEarlyStopping counter: 3 out of 3\nEarly stopping\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# list all files in the current directory\nfiles = os.listdir('.')\n\n# filter the ones that start with 'CORE_baseline'\ncore_models = [f for f in files if f.startswith('dischargeBERT_baseline_MP')]\n\nif core_models:\n    print(\"Found models starting with 'dischargeBERT_baseline_MP':\")\n    for model in core_models:\n        print(model)\n        \n    # get the first (and supposedly only) model\n    model_path = core_models[0]\n\n    # load the model state\n    ensemble_model.load_state_dict(torch.load(model_path))\n    print(\"Loaded Model\")\nelse:\n    print(\"No models found starting with 'dischargeBERT_baseline_MP'.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-06T00:07:00.066897Z","iopub.execute_input":"2024-10-06T00:07:00.067344Z","iopub.status.idle":"2024-10-06T00:07:00.325767Z","shell.execute_reply.started":"2024-10-06T00:07:00.067294Z","shell.execute_reply":"2024-10-06T00:07:00.324874Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3471031453.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ensemble_model.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"name":"stdout","text":"Found models starting with 'dischargeBERT_baseline_MP':\ndischargeBERT_baseline_MP_epoch_2roc_0.8035795639440286.pth\ndischargeBERT_baseline_MP_epoch_4roc_0.8181858558851727.pth\ndischargeBERT_baseline_MP_epoch_3roc_0.8119251369820846.pth\ndischargeBERT_baseline_MP_epoch_7roc_0.8195442432344482.pth\ndischargeBERT_baseline_MP_epoch_1roc_0.7978359908883826.pth\ndischargeBERT_baseline_MP_epoch_0roc_0.7379372213085197.pth\nLoaded Model\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.nn import functional as F\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\n# Put the model in evaluation mode\nensemble_model.eval()\n\n# Initialize lists to store predictions and true labels\ntest_preds = []\ntest_labels = []\n\n# Iterate over test data\nwith torch.no_grad():\n    for batch in tqdm(test_loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = ensemble_model(input_ids, attention_mask)\n        test_preds.append(F.softmax(outputs, dim=1).cpu().numpy())\n        test_labels.append(labels.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2024-10-06T00:07:00.326972Z","iopub.execute_input":"2024-10-06T00:07:00.327364Z","iopub.status.idle":"2024-10-06T00:12:06.444450Z","shell.execute_reply.started":"2024-10-06T00:07:00.327328Z","shell.execute_reply":"2024-10-06T00:12:06.443546Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"100%|██████████| 546/546 [05:06<00:00,  1.78it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_preds = np.concatenate(test_preds)\ntest_labels = np.concatenate(test_labels)\n\n# Calculate metrics\ntest_preds_class = np.argmax(test_preds, axis=1)\naccuracy = accuracy_score(test_labels, test_preds_class)\nrecall = recall_score(test_labels, test_preds_class)\nprecision = precision_score(test_labels, test_preds_class)\nf1 = f1_score(test_labels, test_preds_class)\nroc_auc = roc_auc_score(test_labels, test_preds[:, 1])\n\nprint(f'Accuracy: {accuracy}, Recall: {recall}, Precision: {precision}, F1: {f1}, Roc Auc: {roc_auc}')","metadata":{"execution":{"iopub.status.busy":"2024-10-06T00:12:06.445739Z","iopub.execute_input":"2024-10-06T00:12:06.446138Z","iopub.status.idle":"2024-10-06T00:12:06.481322Z","shell.execute_reply.started":"2024-10-06T00:12:06.446093Z","shell.execute_reply":"2024-10-06T00:12:06.480373Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Accuracy: 0.9014457340663816, Recall: 0.0721951219512195, Precision: 0.8131868131868132, F1: 0.13261648745519714, Roc Auc: 0.8191845335300004\n","output_type":"stream"}]}]}